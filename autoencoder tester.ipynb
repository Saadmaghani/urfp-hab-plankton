{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import Preprocessor\n",
    "from training import Trainer\n",
    "from metrics import Metrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models.autoencoders import Simple_AE, VAE\n",
    "from configuration import Hyperparameters as HP\n",
    "import torch\n",
    "import json\n",
    "import math\n",
    "\n",
    "years = [str(y) for y in range(2006, 2015)]\n",
    "\n",
    "classes = [\"detritus\", \"Leptocylindrus\", \"Chaetoceros\", \"Rhizosolenia\", \"Guinardia_delicatula\", \"Cerataulina\", \"Cylindrotheca\",\n",
    "    \"Skeletonema\", \"Dactyliosolen\", \"Thalassiosira\", \"Dinobryon\", \"Corethron\", \"Thalassionema\", \"Ditylum\", \"pennate\", \"Prorocentrum\",\n",
    "    \"Pseudonitzschia\", \"Tintinnid\", \"Guinardia_striata\", \"Phaeocystis\"]\n",
    "\n",
    "all_classes = [\"mix\", \"detritus\", \"Leptocylindrus\", \"mix_elongated\", \"Chaetoceros\", \"dino30\", \"Rhizosolenia\", \"Guinardia_delicatula\", \n",
    "\"Cerataulina\", \"Cylindrotheca\", \"Skeletonema\", \"Ciliate_mix\", \"Dactyliosolen\", \"Thalassiosira\", \"bad\", \"Dinobryon\", \"Corethron\", \n",
    "\"DactFragCerataul\", \"Thalassionema\", \"Ditylum\", \"pennate\", \"Prorocentrum\", \"Pseudonitzschia\", \"Mesodinium_sp\", \"G_delicatula_parasite\", \n",
    "\"Tintinnid\", \"Guinardia_striata\", \"Phaeocystis\", \"Dictyocha\", \"Pleurosigma\", \"Eucampia\", \"Thalassiosira_dirty\", \n",
    "\"Asterionellopsis\", \"flagellate_sp3\", \"Laboea_strobila\", \"Chaetoceros_didymus_flagellate\", \"Heterocapsa_triquetra\", \"Guinardia_flaccida\", \n",
    "\"Chaetoceros_pennate\", \"Ceratium\", \"Euglena\", \"Coscinodiscus\", \"Strombidium_morphotype1\", \"Paralia\", \"Gyrodinium\", \"Ephemera\", \"Pyramimonas_longicauda\", \n",
    "\"Proterythropsis_sp\", \"Gonyaulax\", \"kiteflagellates\", \"Chrysochromulina\", \"Chaetoceros_didymus\", \"bead\", \"Katodinium_or_Torodinium\", \"Leptocylindrus_mediterraneus\", \n",
    "\"spore\", \"Tontonia_gracillima\", \"Delphineis\", \"Dinophysis\", \"Strombidium_morphotype2\", \"Licmophora\", \"Lauderia\", \"clusterflagellate\", \"Strobilidium_morphotype1\", \n",
    "\"Leegaardiella_ovalis\", \"pennate_morphotype1\", \"amoeba\", \"Strombidium_inclinatum\", \"Pseudochattonella_farcimen\", \"Amphidinium_sp\", \"dino_large1\", \n",
    "\"Strombidium_wulffi\", \"Chaetoceros_flagellate\", \"Strombidium_oculatum\", \"Cerataulina_flagellate\", \"Emiliania_huxleyi\", \"Pleuronema_sp\", \"Strombidium_conicum\",\n",
    " \"Odontella\", \"Protoperidinium\", \"zooplankton\", \"Stephanopyxis\", \"Tontonia_appendiculariformis\", \"Strombidium_capitatum\", \"Bidulphia\", \"Euplotes_sp\", \n",
    " \"Parvicorbicula_socialis\", \"bubble\", \"Hemiaulus\", \"Didinium_sp\", \"pollen\", \"Tiarina_fusus\", \"Bacillaria\", \"Cochlodinium\", \"Akashiwo\", \"Karenia\"]\n",
    "\n",
    "classes_30 = [\"Asterionellopsis\", \"bad\", \"Chaetoceros\", \"Chaetoceros_flagellate\", \"Ciliate_mix\", \"Corethron\", \"Cylindrotheca\", \"Dictyocha\",\"dino30\", \"detritus\",\n",
    "\t\"Dinobryon\", \"Ditylum\", \"Eucampia\", \"flagellate_sp3\", \"Guinardia_delicatula\", \"Guinardia_flaccida\", \"Guinardia_striata\", \"Heterocapsa_triquetra\", \"Laboea_strobila\", \"Leptocylindrus\",\n",
    "\t\"pennate\", \"Phaeocystis\", \"Pleurosigma\", \"Prorocentrum\", \"Pseudonitzschia\", \"Skeletonema\", \"Thalassionema\", \"Thalassiosira\", \"Thalassiosira_dirty\", \"Tintinnid\"]\n",
    "\n",
    "classes_vae = [\"Chaetoceros_flagellate\"]\n",
    "\n",
    "print(len(classes_30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  SIMPLE AUTOENCODER  \"\"\"\n",
    "#pp = Preprocessor(years, include_classes=classes, train_eg_per_class=HP.number_of_images_per_class)\n",
    "#pp = Preprocessor(years, include_classes=all_classes, train_eg_per_class=HP.number_of_images_per_class, thresholding=HP.thresholding)\n",
    "pp = Preprocessor(years, include_classes=classes_30, strategy = HP.pp_strategy, train_eg_per_class=HP.number_of_images_per_class, maxN = HP.maxN, minimum = HP.minimum, transformations = HP.transformations)\n",
    "\n",
    "\n",
    "pp.create_datasets([0.6,0.2,0.2])\n",
    "\n",
    "trainLoader = pp.get_loaders('train', HP.batch_size)\n",
    "validLoader = pp.get_loaders('validation', HP.batch_size)\n",
    "testLoader = pp.get_loaders('test', HP.batch_size)\n",
    "\n",
    "\n",
    "trainer = Trainer(HP_version = HP.version, epochs = HP.number_of_epochs, loss_fn = HP.loss_function, \n",
    "\toptimizer = HP.optimizer, scheduler = HP.scheduler, lr = HP.learning_rate, momentum = HP.momentum, useCuda=True, autoencoder=True)\n",
    "\n",
    "model = Simple_AE()\n",
    "\n",
    "trainAcc = []\n",
    "validAcc = [] \n",
    "epochs = 0 \n",
    "\n",
    "\n",
    "path_to_statedict = \"models/Simple_AE_3.0-10.1.pth\"\n",
    "\n",
    "if \".tar\" in path_to_statedict:\n",
    "    model = trainer.load_partial_model(model, path_to_statedict)\n",
    "else:\n",
    "    model = trainer.load_full_model(model, path_to_statedict)\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "model.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data in testLoader:\n",
    "    inputs, label = data['image'].to(device).float(), data['label']\n",
    "    rand = random.randint(0,127)\n",
    "    img = inputs[rand]\n",
    "    lbl = label[rand]\n",
    "    img = img.reshape((1,1,128,264))\n",
    "    out = model(img)\n",
    "    out_latent = model.get_latent(img)\n",
    "    break\n",
    "\n",
    "np_out = out[0].repeat((3,1,1)).permute(1,2,0).detach().cpu().numpy()\n",
    "np_img = img[0].repeat((3,1,1)).permute(1,2,0).detach().cpu().numpy()\n",
    "\n",
    "print(np_img.shape)\n",
    "print(lbl)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.imshow(np_img, cmap=\"gray\")\n",
    "ax2.imshow(np_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainer.test_autoencoder(model, testLoader)\n",
    "torch.mean(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "149\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VAE:\n\tsize mismatch for enc.linear.weight: copying a param with shape torch.Size([256, 32768]) from checkpoint, the shape in current model is torch.Size([128, 32768]).\n\tsize mismatch for enc.linear.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for enc.mu.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for enc.mu.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for enc.var.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for enc.var.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for dec.linear.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 256]).\n\tsize mismatch for dec.linear.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for dec.out.weight: copying a param with shape torch.Size([32768, 256]) from checkpoint, the shape in current model is torch.Size([32768, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d4615c46c6e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_partial_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_statedict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_full_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_statedict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/saad/urfp-hab-plankton/training.py\u001b[0m in \u001b[0;36mload_full_model\u001b[0;34m(self, model, path_to_statedict)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_full_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_statedict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_statedict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/redtide/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 777\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VAE:\n\tsize mismatch for enc.linear.weight: copying a param with shape torch.Size([256, 32768]) from checkpoint, the shape in current model is torch.Size([128, 32768]).\n\tsize mismatch for enc.linear.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for enc.mu.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for enc.mu.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for enc.var.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for enc.var.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for dec.linear.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 256]).\n\tsize mismatch for dec.linear.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for dec.out.weight: copying a param with shape torch.Size([32768, 256]) from checkpoint, the shape in current model is torch.Size([32768, 128])."
     ]
    }
   ],
   "source": [
    "\"\"\" Variational Autoencoder  \"\"\"\n",
    "\n",
    "#pp = Preprocessor(years, include_classes=classes, train_eg_per_class=HP.number_of_images_per_class)\n",
    "#pp = Preprocessor(years, include_classes=all_classes, train_eg_per_class=HP.number_of_images_per_class, thresholding=HP.thresholding)\n",
    "pp = Preprocessor(years, include_classes=classes_vae, strategy = HP.pp_strategy, train_eg_per_class=HP.number_of_images_per_class, maxN = HP.maxN, minimum = HP.minimum, transformations = HP.transformations)\n",
    "\n",
    "\n",
    "pp.create_datasets([0.8,0.1,0.1])\n",
    "\n",
    "trainLoader = pp.get_loaders('train', HP.batch_size)\n",
    "validLoader = pp.get_loaders('validation', HP.batch_size)\n",
    "testLoader = pp.get_loaders('test', HP.batch_size)\n",
    "\n",
    "\n",
    "trainer = Trainer(HP_version = HP.version, epochs = HP.number_of_epochs, loss_fn = HP.loss_function, \n",
    "\toptimizer = HP.optimizer, scheduler = HP.scheduler, lr = HP.learning_rate, momentum = HP.momentum, useCuda=True, autoencoder=True)\n",
    "\n",
    "model = VAE()\n",
    "\n",
    "\n",
    "path_to_statedict = \"models/VAE_2.0-12.1.pth\"\n",
    "\n",
    "if \".tar\" in path_to_statedict:\n",
    "    model = trainer.load_partial_model(model, path_to_statedict)\n",
    "else:\n",
    "    model = trainer.load_full_model(model, path_to_statedict)\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "model.to(device)\n",
    "\n",
    "sample = model.get_sample()\n",
    "\n",
    "sample = sample.view(128, 256).data\n",
    "\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data in testLoader:\n",
    "    inputs, label = data['image'].to(device).float(), data['label']\n",
    "    rand = random.randint(0,127)\n",
    "    img = inputs[rand]\n",
    "    lbl = label[rand]\n",
    "    img = img.reshape((1,1,128,256))\n",
    "    break\n",
    "\n",
    "np_img = img[0].repeat((3,1,1)).permute(1,2,0).detach().cpu().numpy()\n",
    "\n",
    "print(np_img.shape)\n",
    "print(lbl)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.imshow(np_img, cmap=\"gray\")\n",
    "ax2.imshow(sample)\n",
    "\n",
    "\n",
    "x = trainer.test_autoencoder(model, testLoader)\n",
    "torch.mean(x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
