{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import Preprocessor\n",
    "from training import Trainer\n",
    "from metrics import Metrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models.vgg_TL import GoogleNet, VGG, ResNet\n",
    "from models.autoencoders import Simple_AE\n",
    "from configuration import Hyperparameters as HP\n",
    "import torch\n",
    "import json\n",
    "import math\n",
    "\n",
    "years = [str(y) for y in range(2006, 2015)]\n",
    "\n",
    "classes = [\"detritus\", \"Leptocylindrus\", \"Chaetoceros\", \"Rhizosolenia\", \"Guinardia_delicatula\", \"Cerataulina\", \"Cylindrotheca\",\n",
    "    \"Skeletonema\", \"Dactyliosolen\", \"Thalassiosira\", \"Dinobryon\", \"Corethron\", \"Thalassionema\", \"Ditylum\", \"pennate\", \"Prorocentrum\",\n",
    "    \"Pseudonitzschia\", \"Tintinnid\", \"Guinardia_striata\", \"Phaeocystis\"]\n",
    "\n",
    "all_classes = [\"mix\", \"detritus\", \"Leptocylindrus\", \"mix_elongated\", \"Chaetoceros\", \"dino30\", \"Rhizosolenia\", \"Guinardia_delicatula\", \n",
    "\"Cerataulina\", \"Cylindrotheca\", \"Skeletonema\", \"Ciliate_mix\", \"Dactyliosolen\", \"Thalassiosira\", \"bad\", \"Dinobryon\", \"Corethron\", \n",
    "\"DactFragCerataul\", \"Thalassionema\", \"Ditylum\", \"pennate\", \"Prorocentrum\", \"Pseudonitzschia\", \"Mesodinium_sp\", \"G_delicatula_parasite\", \n",
    "\"Tintinnid\", \"Guinardia_striata\", \"Phaeocystis\", \"Dictyocha\", \"Pleurosigma\", \"Eucampia\", \"Thalassiosira_dirty\", \n",
    "\"Asterionellopsis\", \"flagellate_sp3\", \"Laboea_strobila\", \"Chaetoceros_didymus_flagellate\", \"Heterocapsa_triquetra\", \"Guinardia_flaccida\", \n",
    "\"Chaetoceros_pennate\", \"Ceratium\", \"Euglena\", \"Coscinodiscus\", \"Strombidium_morphotype1\", \"Paralia\", \"Gyrodinium\", \"Ephemera\", \"Pyramimonas_longicauda\", \n",
    "\"Proterythropsis_sp\", \"Gonyaulax\", \"kiteflagellates\", \"Chrysochromulina\", \"Chaetoceros_didymus\", \"bead\", \"Katodinium_or_Torodinium\", \"Leptocylindrus_mediterraneus\", \n",
    "\"spore\", \"Tontonia_gracillima\", \"Delphineis\", \"Dinophysis\", \"Strombidium_morphotype2\", \"Licmophora\", \"Lauderia\", \"clusterflagellate\", \"Strobilidium_morphotype1\", \n",
    "\"Leegaardiella_ovalis\", \"pennate_morphotype1\", \"amoeba\", \"Strombidium_inclinatum\", \"Pseudochattonella_farcimen\", \"Amphidinium_sp\", \"dino_large1\", \n",
    "\"Strombidium_wulffi\", \"Chaetoceros_flagellate\", \"Strombidium_oculatum\", \"Cerataulina_flagellate\", \"Emiliania_huxleyi\", \"Pleuronema_sp\", \"Strombidium_conicum\",\n",
    " \"Odontella\", \"Protoperidinium\", \"zooplankton\", \"Stephanopyxis\", \"Tontonia_appendiculariformis\", \"Strombidium_capitatum\", \"Bidulphia\", \"Euplotes_sp\", \n",
    " \"Parvicorbicula_socialis\", \"bubble\", \"Hemiaulus\", \"Didinium_sp\", \"pollen\", \"Tiarina_fusus\", \"Bacillaria\", \"Cochlodinium\", \"Akashiwo\", \"Karenia\"]\n",
    "\n",
    "classes_30 = [\"Asterionellopsis\", \"bad\", \"Chaetoceros\", \"Chaetoceros_flagellate\", \"Ciliate_mix\", \"Corethron\", \"Cylindrotheca\", \"Dictyocha\",\"dino30\", \"detritus\",\n",
    "\t\"Dinobryon\", \"Ditylum\", \"Eucampia\", \"flagellate_sp3\", \"Guinardia_delicatula\", \"Guinardia_flaccida\", \"Guinardia_striata\", \"Heterocapsa_triquetra\", \"Laboea_strobila\", \"Leptocylindrus\",\n",
    "\t\"pennate\", \"Phaeocystis\", \"Pleurosigma\", \"Prorocentrum\", \"Pseudonitzschia\", \"Skeletonema\", \"Thalassionema\", \"Thalassiosira\", \"Thalassiosira_dirty\", \"Tintinnid\"]\n",
    "\n",
    "print(len(classes_30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp = Preprocessor(years, include_classes=classes, train_eg_per_class=HP.number_of_images_per_class)\n",
    "#pp = Preprocessor(years, include_classes=all_classes, train_eg_per_class=HP.number_of_images_per_class, thresholding=HP.thresholding)\n",
    "pp = Preprocessor(years, include_classes=classes_30, strategy = HP.pp_strategy, train_eg_per_class=HP.number_of_images_per_class, maxN = HP.maxN, minimum = HP.minimum, transformations = HP.transformations)\n",
    "\n",
    "\n",
    "pp.create_datasets([0.6,0.2,0.2])\n",
    "\n",
    "trainLoader = pp.get_loaders('train', HP.batch_size)\n",
    "validLoader = pp.get_loaders('validation', HP.batch_size)\n",
    "testLoader = pp.get_loaders('test', HP.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sd(model, path_to_statedict):\n",
    "    state_dict = torch.load(path_to_statedict, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model_gn = GoogleNet()\n",
    "model_vgg = VGG()\n",
    "model_resnet = ResNet()\n",
    "\n",
    "model_gn = load_sd(model_gn, \"models/GoogleNet_1.2-4.3.pth\")\n",
    "model_vgg = load_sd(model_vgg, \"models/VGG_2.0-4.3.pth\")\n",
    "model_resnet = load_sd(model_resnet, \"models/ResNet_2.0-4.3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_gn, model_vgg, model_resnet ,testloader):\n",
    "    all_preds = torch.LongTensor().to(self.device)\n",
    "    all_targets = torch.LongTensor().to(self.device)\n",
    "\n",
    "    all_fnames = []\n",
    "    model.to(self.device)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in testloader:\n",
    "            inputs, labels = data['image'].to(self.device).float(), data['encoded_label'].to(self.device).float()\n",
    "\n",
    "            _, labels = torch.max(labels, 1)\n",
    "\n",
    "            out_gn = model_gn(inputs)\n",
    "            out_vgg = model_vgg(inputs)\n",
    "            out_resnet = model_resnet(inputs)\n",
    "            \n",
    "            print()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(\"labels:\", labels)\n",
    "            #print(\"predicted:\", predicted)\n",
    "            #print(\"~~~~~~~~~~~~~~~~\")\n",
    "            all_preds = torch.cat((all_preds, predicted), 0)\n",
    "            all_targets = torch.cat((all_targets, labels), 0) \n",
    "\n",
    "            #if total >=10:\n",
    "            #   break\n",
    "\n",
    "            all_fnames.extend(data['fname'])\n",
    "\n",
    "    return all_preds, all_targets, all_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_gn, model_vgg, model_resnet, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(HP_version = HP.version, epochs = HP.number_of_epochs, loss_fn = HP.loss_function, optimizer = HP.optimizer, \n",
    "\tscheduler = HP.scheduler, lr = HP.learning_rate, momentum = HP.momentum, useCuda=True, autoencoder=HP.train_AE)\n",
    "\n",
    "\n",
    "# using autoencoder\n",
    "ae = Simple_AE()\n",
    "path_to_ae = \"../Simple_AE_3.0-10.1.pth\"\n",
    "\n",
    "if \".tar\" in path_to_ae:\n",
    "    ae = trainer.load_partial_model(ae, path_to_ae)\n",
    "else:\n",
    "    ae = trainer.load_full_model(ae, path_to_ae)\n",
    "\n",
    "model = GoogleNet(autoencoder = ae)\n",
    "\n",
    "\n",
    "trainAcc = []\n",
    "validAcc = [] \n",
    "epochs = 0 \n",
    "\n",
    "trainAcc, validAcc, epochs = trainer.train(model, trainLoader, validLoader, earlyStopping = HP.es)\n",
    "\n",
    "# - or -\n",
    "\"\"\"\n",
    "path_to_statedict = \"models/GoogleNet_2.0-8.0.tar\"\n",
    "\n",
    "if \".tar\" in path_to_statedict:\n",
    "    model = trainer.load_partial_model(model, path_to_statedict)\n",
    "else:\n",
    "    model = trainer.load_full_model(model, path_to_statedict)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# autoencoder stuff:\n",
    "\"\"\"\n",
    "test_sumsqs, test_fnames = trainer.test_autoencoder(model, testLoader)\n",
    "test_acc = torch.mean(test_sumsqs).tolist()\n",
    "\"\"\"\n",
    "\n",
    "test_pred, test_target, test_fnames = trainer.test(model, testLoader)\n",
    "#valid_pred, valid_target, valid_fnames = trainer.test(model, validLoader)\n",
    "#train_pred, train_target, train_fnames = trainer.test(model, trainLoader)\n",
    "\n",
    "\n",
    "test_met = Metrics(test_target, test_pred)\n",
    "#valid_met = Metrics(valid_target, valid_pred)\n",
    "#train_met = Metrics(train_target, train_pred)\n",
    "\n",
    "test_acc = test_met.accuracy()\n",
    "print(test_met.accuracy())\n",
    "\n",
    "print(test_acc)\n",
    "\n",
    "#time = trainer.getTime()\n",
    "time = \"xx:xx:xx\"\n",
    "print(time)\n",
    "\n",
    "f = open(\"./stats/stats-\"+str(model)+\"-\"+str(HP.version)+\".json\",\"w+\")\n",
    "\n",
    "#str(test_met.accuracy()) + \\\n",
    "\n",
    "str_to_write = \"{\\\"Time\\\": \\\"\"+ time +\"\\\",\\n \\\"Epochs\\\": \"+str(epochs)+ \",\\n \\\"TrainAcc\\\": \"+ str(trainAcc)+\",\\n \\\"ValidAcc\\\": \"+str(validAcc)+\",\\n \\\"TestAcc\\\": \"+ str(test_acc) + \"}\"\n",
    "#\",\\n \\\"Train_Pred\\\": \" + str(list(train_pred.cpu().numpy())) + \",\\n \\\"Train_Target\\\": \" + str(list(train_target.cpu().numpy())) + \",\\n \\\"Train_fnames\\\": \" + json.dumps(train_fnames) + \\\n",
    "#\",\\n \\\"Valid_Pred\\\": \" + str(list(valid_pred.cpu().numpy())) + \",\\n \\\"Valid_Target\\\": \" + str(list(valid_target.cpu().numpy())) + \",\\n \\\"Valid_fnames\\\": \" + json.dumps(valid_fnames) + \\\n",
    "#\",\\n \\\"Test_Pred\\\": \" + str(list(test_pred.cpu().numpy())) + \",\\n \\\"Test_Target\\\": \" + str(list(test_target.cpu().numpy())) + \",\\n \\\"Test_fnames\\\": \" + json.dumps(test_fnames) + \\\n",
    "#\"}\"\n",
    "f.write(str_to_write)\n",
    "f.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
